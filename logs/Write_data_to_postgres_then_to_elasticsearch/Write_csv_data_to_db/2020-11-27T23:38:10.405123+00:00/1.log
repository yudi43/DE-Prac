[2020-11-28 05:08:20,483] {taskinstance.py:670} INFO - Dependencies all met for <TaskInstance: Write_data_to_postgres_then_to_elasticsearch.Write_csv_data_to_db 2020-11-27T23:38:10.405123+00:00 [queued]>
[2020-11-28 05:08:20,504] {taskinstance.py:670} INFO - Dependencies all met for <TaskInstance: Write_data_to_postgres_then_to_elasticsearch.Write_csv_data_to_db 2020-11-27T23:38:10.405123+00:00 [queued]>
[2020-11-28 05:08:20,504] {taskinstance.py:880} INFO - 
--------------------------------------------------------------------------------
[2020-11-28 05:08:20,504] {taskinstance.py:881} INFO - Starting attempt 1 of 1
[2020-11-28 05:08:20,504] {taskinstance.py:882} INFO - 
--------------------------------------------------------------------------------
[2020-11-28 05:08:20,517] {taskinstance.py:901} INFO - Executing <Task(PythonOperator): Write_csv_data_to_db> on 2020-11-27T23:38:10.405123+00:00
[2020-11-28 05:08:20,520] {standard_task_runner.py:54} INFO - Started process 62980 to run task
[2020-11-28 05:08:20,545] {standard_task_runner.py:77} INFO - Running: ['airflow', 'run', 'Write_data_to_postgres_then_to_elasticsearch', 'Write_csv_data_to_db', '2020-11-27T23:38:10.405123+00:00', '--job_id', '362', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/dag.py', '--cfg_path', '/var/folders/ff/pqhf5klx0msdsn3m1cnq4cxr0000gn/T/tmpgbiz8d9_']
[2020-11-28 05:08:20,547] {standard_task_runner.py:78} INFO - Job 362: Subtask Write_csv_data_to_db
[2020-11-28 05:08:20,593] {logging_mixin.py:112} INFO - Running %s on host %s <TaskInstance: Write_data_to_postgres_then_to_elasticsearch.Write_csv_data_to_db 2020-11-27T23:38:10.405123+00:00 [running]> 47.43.168.192.in-addr.arpa
[2020-11-28 05:08:20,625] {taskinstance.py:1150} ERROR - [Errno 2] No such file or directory: 'test.csv'
Traceback (most recent call last):
  File "/Users/yudi/opt/anaconda3/envs/airflow/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 984, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/Users/yudi/opt/anaconda3/envs/airflow/lib/python3.6/site-packages/airflow/operators/python_operator.py", line 113, in execute
    return_value = self.execute_callable()
  File "/Users/yudi/opt/anaconda3/envs/airflow/lib/python3.6/site-packages/airflow/operators/python_operator.py", line 118, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/Users/yudi/workspace/personalprojects/DE-Prac/Airflow_prac/csv_to_postgres_to_elasticsearch/dag.py", line 42, in write_data
    with open("test.csv", "r") as f:
FileNotFoundError: [Errno 2] No such file or directory: 'test.csv'
[2020-11-28 05:08:20,628] {taskinstance.py:1194} INFO - Marking task as FAILED. dag_id=Write_data_to_postgres_then_to_elasticsearch, task_id=Write_csv_data_to_db, execution_date=20201127T233810, start_date=20201127T233820, end_date=20201127T233820
[2020-11-28 05:08:25,468] {local_task_job.py:102} INFO - Task exited with return code 1
