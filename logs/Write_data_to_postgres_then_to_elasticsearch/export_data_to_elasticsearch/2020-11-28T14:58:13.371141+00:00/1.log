[2020-11-28 20:28:32,843] {taskinstance.py:670} INFO - Dependencies all met for <TaskInstance: Write_data_to_postgres_then_to_elasticsearch.export_data_to_elasticsearch 2020-11-28T14:58:13.371141+00:00 [queued]>
[2020-11-28 20:28:32,872] {taskinstance.py:670} INFO - Dependencies all met for <TaskInstance: Write_data_to_postgres_then_to_elasticsearch.export_data_to_elasticsearch 2020-11-28T14:58:13.371141+00:00 [queued]>
[2020-11-28 20:28:32,872] {taskinstance.py:880} INFO - 
--------------------------------------------------------------------------------
[2020-11-28 20:28:32,872] {taskinstance.py:881} INFO - Starting attempt 1 of 1
[2020-11-28 20:28:32,872] {taskinstance.py:882} INFO - 
--------------------------------------------------------------------------------
[2020-11-28 20:28:32,880] {taskinstance.py:901} INFO - Executing <Task(BashOperator): export_data_to_elasticsearch> on 2020-11-28T14:58:13.371141+00:00
[2020-11-28 20:28:32,882] {standard_task_runner.py:54} INFO - Started process 57043 to run task
[2020-11-28 20:28:32,905] {standard_task_runner.py:77} INFO - Running: ['airflow', 'run', 'Write_data_to_postgres_then_to_elasticsearch', 'export_data_to_elasticsearch', '2020-11-28T14:58:13.371141+00:00', '--job_id', '502', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/csv_pg_elasticsearch.py', '--cfg_path', '/var/folders/ff/pqhf5klx0msdsn3m1cnq4cxr0000gn/T/tmpwe8e24qy']
[2020-11-28 20:28:32,907] {standard_task_runner.py:78} INFO - Job 502: Subtask export_data_to_elasticsearch
[2020-11-28 20:28:32,953] {logging_mixin.py:112} INFO - Running %s on host %s <TaskInstance: Write_data_to_postgres_then_to_elasticsearch.export_data_to_elasticsearch 2020-11-28T14:58:13.371141+00:00 [running]> 47.43.168.192.in-addr.arpa
[2020-11-28 20:28:32,983] {bash_operator.py:113} INFO - Tmp dir root location: 
 /var/folders/ff/pqhf5klx0msdsn3m1cnq4cxr0000gn/T
[2020-11-28 20:28:32,984] {bash_operator.py:136} INFO - Temporary script location: /var/folders/ff/pqhf5klx0msdsn3m1cnq4cxr0000gn/T/airflowtmp9n35ihz9/export_data_to_elasticsearchgcd1chuk
[2020-11-28 20:28:32,984] {bash_operator.py:146} INFO - Running command: /Users/yudi/ELK/logstash-7.10.0/bin/logstash -f logstash-simple.conf
[2020-11-28 20:28:32,989] {bash_operator.py:153} INFO - Output:
[2020-11-28 20:28:33,014] {bash_operator.py:157} INFO - Using JAVA_HOME defined java: /Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home
[2020-11-28 20:28:33,015] {bash_operator.py:157} INFO - WARNING, using JAVA_HOME while Logstash distribution comes with a bundled JDK
[2020-11-28 20:28:51,935] {bash_operator.py:157} INFO - Sending Logstash logs to /Users/yudi/ELK/logstash-7.10.0/logs which is now configured via log4j2.properties
[2020-11-28 20:28:52,350] {bash_operator.py:157} INFO - [2020-11-28T20:28:52,348][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"7.10.0", "jruby.version"=>"jruby 9.2.13.0 (2.5.7) 2020-08-03 9a89c94bcc OpenJDK 64-Bit Server VM 25.262-b10 on 1.8.0_262-b10 +indy +jit [darwin-x86_64]"}
[2020-11-28 20:28:52,497] {bash_operator.py:157} INFO - [2020-11-28T20:28:52,497][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.queue", :path=>"/Users/yudi/ELK/logstash-7.10.0/data/queue"}
[2020-11-28 20:28:52,525] {bash_operator.py:157} INFO - [2020-11-28T20:28:52,525][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>"path.dead_letter_queue", :path=>"/Users/yudi/ELK/logstash-7.10.0/data/dead_letter_queue"}
[2020-11-28 20:28:52,676] {bash_operator.py:157} INFO - [2020-11-28T20:28:52,675][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified
[2020-11-28 20:28:52,718] {bash_operator.py:157} INFO - [2020-11-28T20:28:52,718][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"a8d4b89b-dda6-4e94-ac7c-821572df9b0a", :path=>"/Users/yudi/ELK/logstash-7.10.0/data/uuid"}
[2020-11-28 20:28:53,474] {bash_operator.py:157} INFO - [2020-11-28T20:28:53,473][INFO ][logstash.config.source.local.configpathloader] No config files found in path {:path=>"/private/var/folders/ff/pqhf5klx0msdsn3m1cnq4cxr0000gn/T/airflowtmp9n35ihz9/logstash-simple.conf"}
[2020-11-28 20:28:53,491] {bash_operator.py:157} INFO - [2020-11-28T20:28:53,491][ERROR][logstash.config.sourceloader] No configuration found in the configured sources.
[2020-11-28 20:28:53,795] {bash_operator.py:157} INFO - [2020-11-28T20:28:53,795][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
[2020-11-28 20:28:58,827] {bash_operator.py:157} INFO - [2020-11-28T20:28:58,826][INFO ][logstash.runner          ] Logstash shut down.
[2020-11-28 20:28:58,837] {bash_operator.py:157} INFO - [2020-11-28T20:28:58,837][ERROR][org.logstash.Logstash    ] java.lang.IllegalStateException: Logstash stopped processing because of an error: (SystemExit) exit
[2020-11-28 20:28:59,254] {bash_operator.py:161} INFO - Command exited with return code 1
[2020-11-28 20:28:59,290] {taskinstance.py:1150} ERROR - Bash command failed
Traceback (most recent call last):
  File "/Users/yudi/opt/anaconda3/envs/airflow/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 984, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/Users/yudi/opt/anaconda3/envs/airflow/lib/python3.6/site-packages/airflow/operators/bash_operator.py", line 165, in execute
    raise AirflowException("Bash command failed")
airflow.exceptions.AirflowException: Bash command failed
[2020-11-28 20:28:59,295] {taskinstance.py:1194} INFO - Marking task as FAILED. dag_id=Write_data_to_postgres_then_to_elasticsearch, task_id=export_data_to_elasticsearch, execution_date=20201128T145813, start_date=20201128T145832, end_date=20201128T145859
[2020-11-28 20:29:02,925] {local_task_job.py:102} INFO - Task exited with return code 1
